概述
    K8s (Kubernetes) 是用于部署、扩展、管理容器的开源系统。
核心概念
    Pod
        Pod 是一组容器的抽象
        Pod 内的不同容器可以通过 localhost 互相访问
    Service
        Service 是一组 Pod 的抽象，是外界对这组 Pod 的访问入口。
            Pod 的新建和销毁可能导致 IP 发生变化，外界直接通过 IP 访问 Pod 就会产生问题。
            Service 服务创建后，外界访问 Service 的 IP ，然后再由 Service 将流量路由到合适的 Pod 。
        Service 对外曝露的方式有：
            ClusterIP 
                以集群内部 IP 对外曝露，这种类型的 Service 只能集群内部访问。
            NodePort
                以每个集群节点端口映射的方式对外曝露，这种类型的 Service 可以从外部访问。
            ...
    Namespace
        Namespace 是一组资源的抽象，提供了一个逻辑隔离的空间。
资源对象
    概述
        资源是 K8s 中所有内容的抽象，如 Pod 、 Service 等都是资源。 K8s 已经内置多种资源，如工作负载、存储资源、网络资源等。
        资源对象就是资源的实例，是持久化的实体，如某个具体的 Pod 、某个具体的 Node 等。 K8s 使用这些实体去表示整个集群的状态。
        资源对象通过配置文件来创建，配置文件是资源对象属性的描述文件，配置文件格式可以是 JSON 、 YAML 等。
    分类
        基本资源
            Pod
            Service
            Volume
        工作负载
            Deployment
            StatefulSet
            DaemonSet
            ReplicaSet
        配置存储
            ConfigMap
                ConfigMap 用于存储键值对，创建之后可以被 Pod 以多种方式引用，例如作为 Pod 的环境变量，或者挂载到 Pod 内部的配置文件。
                ConfigMap 更新后，以环境变量引用的方式需要重启 Pod 才会生效，以文件挂载的方式不需要重启。
            Secret
            PersistentVolume
            PersistentVolumeClaim
        网络资源
            Ingress
            NetworkPolicy
        集群管理
            Node
            Namespace
        用户权限
            Role
        ...
    定制
        资源可以自定义（ Custom Resource Definition ， CRD ）
        CRD 创建后，在 K8s 内仅表现为一个被存储的定义，需要借助用户实现的 Controller 来进一步发挥其作用。
        Controller 可以监听 CRD 资源对象的增删改查事件，用户可以根据这些事件来做不同的处理。
核心组件
    Kubernetes Master
        API Server
            API Server 向外部客户端暴露 K8s 的 API ，外部客户端可以通过这些 API 来发出请求以处理自己的工作。
        Scheduler
            Scheduler 根据集群 Node 的资源信息，将 Pod 调度到合适的 Node 上运行。
        Controller
            Replication Controller
                Replication Controller 用于确保 Pod 的副本数量与期望数量一致，并监控 Pod 的健康状态。
            Node Controller
                Node Controller 用于确保集群中 Node 数量与期望数量一致，并监控 Node 的健康状态。
            ...
        ETCD
            ETCD 是 K8s 集群的后台数据库，内部实现是键值存储，类似 Redis 。
            ETCD 存储的数据包括集群配置、节点状态信息、服务信息、 Pod 信息、事件信息等。
    Kubernetes Node
        Kubelet
            Kubelet 负责与 API Server 通信、容器生命周期管理（通过 Container Runtime 实现）、资源信息（例如计算、内存、存储、网络资源）上报等。
        Kube-proxy
            Kube-proxy 可以实现流量负载均衡的功能，将到达 Service 的流量分配到合适的 Pod 。
                对 Service 的访问可以使用 NodePort 方式
                    NodePort 是将每个节点指定端口的流量，转发到指定的 Service 。
            Kube-proxy 提供的负载均衡主要有两种场景：
                节点外客户端访问 Service
                节点内 Pod 访问 Service
        Container Runtime
            Container Runtime （容器运行时）主要用于容器生命周期的管理，包含容器创建、启动、运行、停止、销毁等，容器运行时的具体实现有 Containerd 、 CRI-O 等。
功能组件
    网络
        Ingress
            Ingress 可以实现流量路由、负载均衡的功能，将到达 Ingress 的流量转发到合适的 Service 。
            Ingress 的功能类似于 Nginx ，先收到外部客户端的请求（一般带有域名），然后根据用户定义的规则，转发到正确的 Service 。
            Ingress 组件包含 Nginx 、 Ingress Controller 、 Ingress 。
                Ingress 是流量路由规则对象
                Nginx 负责流量路由
                Ingress Controller 负责感知路由规则的变化，并动态应用到 Nginx 。
            
        Flannel
        Calico

        相关知识
            OSI
                7 Application layer
                6 Presentation layer
                5 Session layer
                4 Transport layer
                    UDP
                    TCP
                3 Network layer
                    IP
                2 Data link layer
                    Ethernet
                    VLAN
                1 Physical layer
            NAT
            Underlay
            Overlay
            LAN
                LAN （ Local Area Network ，局域网）是指覆盖范围较小的网络
            VLAN
                VLAN （ Virtual Local Area Network ，虚拟局域网）是将一个 LAN 局域网进行划分，形成多个逻辑上独立的虚拟局域网。
            交换机
                二层交换机
                    二层交换机主要用于二层网络（链路层）的互通
                三层交换机
                    三层交换机可以认为是带有路由功能的二层交换机，即用于三层网络（网络层）的互通。
    存储
        分类
            对象存储 OSS
                协议支持 HTTP/HTTPS
            文件存储 NAS
                协议支持 NFS/SMB
            块存储 EBS
                协议支持 SCSI
        实现
            Ceph
    监控
        Prometheus
        Grafana
        ELK
            Elasticsearch
            Logstash
            Kibana
常用命令
    ConfigMap
        列表
            kubectl get configmap -o wide -n <namespace_name>
    StorageClass
        概述
            StorageClass 用于动态创建 PV
        创建
            kubectl apply -f manual-sc.yaml
                -f ：指定配置文件。
        列表
            kubectl get storageclass -o wide
        删除
            kubectl delete storageclass <sc_name>
    PV
        概述
            PV （ Persistent Volume ）是集权存储资源，不特定于某个命名空间。
        创建
            kubectl create -f nfs-pv.yaml
                -f ：指定配置文件。
        列表
            kubectl get pv -o wide
        删除
            kubectl delete pv <pv_name>
    PVC
        概述
            PVC （ Persistent Volume Claim ）是存储资源对象，是用户对存储的声明式请求。
        创建
            kubectl create -f nfs-pvc.yaml -n <namespace_name>
                -f ：指定配置文件。
        列表
            kubectl get pvc -o wide -n <namespace_name>
        删除
            kubectl delete pvc <pvc_name> -n <namespace_name>
    Pod     
        列表
            kubectl get pod -o wide -n <namespace_name>
                进入 Pod
                    kubectl exec -it -n <namespace> <pod_name> -- bash
        详情
            kubectl describe pod <pod_name> 
        重启
            常规方式
                kubectl get pod <pod_name> -n <namespace_name> -o yaml | kubectl replace --force -f -
        删除
            kubectl delete pod --all -n <namespace_name>
    Service 
        创建
            NodePort
                kubectl expose <resource_type> <resource_name> --port=<service_port> --target-port=<pod_port> --type=NodePort
        列表
            kubectl get service -o wide -n <namespace_name>
    Deployment 
        列表
            kubectl get deployment -o wide -n <namespace_name>
        缩放
            kubectl scale deployment/<deployment_name> --replicas=<target_number>
    Namespace 
        创建
            kubectl create namespace <namespace_name>
        列表
            kubectl get namespace -o wide

开发环境（ https://bbs.huaweicloud.com/blogs/380596 ）
    前置条件
        Ubuntu 20.04.6 LTS
            192.168.233.129   hadoop01
            192.168.233.130   hadoop02
            192.168.233.131   hadoop03

            sudo vim /etc/hostname
                配置主机名
                三台主机都要进行配置
                需要重启
            sudo vim /etc/hosts
                配置主机列表
                三台主机都要进行配置
                追加或更新
                    192.168.233.129 hadoop01
                    192.168.233.130 hadoop02
                    192.168.233.131 hadoop03
                需要重启
        规划资源
            Master   hadoop01   192.168.233.129
            Node     hadoop02   192.168.233.130
            Node     hadoop03   192.168.233.131
        用户权限
            sudo su
        关闭 Swap （ hadoop01/hadoop02/hadoop03 ， Swap 会影响容器性能）
            swapoff -a
            sed -ri 's/.*swap.*/#&/' /etc/fstab
                -r ：启用正则表达式。
                -i ：原地编辑。
                's/.*swap.*/#&/' ：替换命令，在包含 swap 的行前加 # ，即注释掉该行。
                /etc/fstab ：要编辑的文件路径。
        桥接网络（ hadoop01/hadoop02/hadoop03 ，确保容器网络进出都经过 ip6tables/iptables ，以应用网络安全规则）
            cat > /etc/sysctl.d/k8s.conf << EOF
            net.bridge.bridge-nf-call-ip6tables = 1
            net.bridge.bridge-nf-call-iptables = 1
            EOF

            sysctl --system

    安装 Docker （ hadoop01/hadoop02/hadoop03 ， 20.10.16 ）
        略
            参考 docker-demo

        systemctl enable docker
            添加开机自启

        vim /etc/docker/daemon.json
            追加
                {
                  ...
                  "exec-opts": ["native.cgroupdriver=systemd"]
                }
                    告诉 Docker 使用 systemd 作为其 cgroup 驱动程序，这样做的目的是为了与宿主系统的 cgroup 配置保持一致，以便更好地管理容器的资源。

            systemctl daemon-reload
                重新加载 systemd 守护程序的配置文件
            systemctl restart docker

    安装 K8s 核心组件（ hadoop01/hadoop02/hadoop03 ）
        curl http://mirrors.huaweicloud.com/kubernetes/yum/doc/apt-key.gpg | apt-key add -
            添加 K8s GPG 密钥到受信任列表

        cat > /etc/apt/sources.list.d/kubernetes.list << EOF
        deb http://mirrors.huaweicloud.com/kubernetes/apt/ kubernetes-xenial main
        EOF
            添加 k8s 镜像源

        apt update
        apt install -y kubelet=1.23.9-00 kubeadm=1.23.9-00 kubectl=1.23.9-00
        systemctl enable kubelet

    启动 K8s 集群（ hadoop01 ）
        kubeadm init \
        --apiserver-advertise-address=192.168.233.129 \
        --image-repository registry.aliyuncs.com/google_containers \
        --pod-network-cidr=10.244.0.0/16 \
        --ignore-preflight-errors='all'
            初始化 K8s Master ，执行之后需要按照控制台提示进行操作。

        kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
            安装网络组件 Flannel ，为集群提供虚拟网络，让各节点上的 Pod 之间可以互相通信。
            建议 docker 使用 socks5 代理的情况下安装 Flannel
            如果安装失败，通过以下命令删除后再重试：
                kubectl delete -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

    加入 K8s 集群（ hadoop02/hadoop03 ）
        kubeadm join 192.168.233.129:6443 --token <token> \
                --discovery-token-ca-cert-hash sha256:<sha256>

    安装 K8s Dashboard （ hadoop01 ， 2.5.1 ， https://skyao.io/learning-kubernetes/docs/installation/kubeadm/dashboard ）
        kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml
            安装完成后，是以 ClusterIP 的形式对外曝露服务，只能在集群内部访问，需要将 ClusterIP 更新为 NodePort ：
                kubectl -n kubernetes-dashboard edit service kubernetes-dashboard
                    更新
                        spec:
                            ...
                            type: NodePort
            查看 Dashboard 所在节点：
                kubectl get pods -A -o wide | grep kubernetes-dashboard
            查看 Dashboard 所在端口：
                kubectl -n kubernetes-dashboard get service kubernetes-dashboard
            获取 Dashboard 登录 token
                kubectl -n kube-system describe $(kubectl -n kube-system get secret -n kube-system -o name | grep namespace) | grep token
            登录 Dashboard
                https://<ip>:<port>
                    如果浏览器因为安全问题无法进入，可以在页面空白处输入以下内容即可：
                        thisisunsafe

    部署应用
        简单示例
            kubectl create deployment nginx --image=nginx
                创建部署

                kubectl expose deployment nginx --port=80 --type=NodePort
                    服务曝露
                kubectl scale -n default deployment nginx --replicas=2
                    服务伸缩
                验证
                    kubectl get service -A -o wide
                        服务端口查看
                            http://<any_cluster_node_ip>:<port>