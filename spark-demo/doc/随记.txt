环境
    独立部署（3.0.0）
        独立部署模式由Spark自身提供计算资源，无需其它框架提供资源，这种模式降低了与其它框架的耦合性。
        前置条件
            三台服务器（Ubuntu 20.04.6 LTS）
                192.168.233.129 hadoop01
                192.168.233.130 hadoop02
                192.168.233.131 hadoop03
        准备文件（hadoop01）
            sudo mkdir /opt/module/spark 
            sudo chown -R sxydh:sxydh /opt/module/spark
            wget -P /opt/module/spark https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz
            tar -zxvf /opt/module/spark/spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module/spark
        修改配置文件（hadoop01）
            cp /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/slaves.template /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/slaves
            vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/slaves
                更新
                    hadoop01
                    hadoop02
                    hadoop03
            cp /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh.template /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh
            vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh
                追加
                    export JAVA_HOME=/opt/module/jdk/jdk1.8.0_202
                    export SPARK_MASTER_HOST=hadoop01
                    export SPARK_MASTER_PORT=7077
        分发文件到集群（hadoop02，hadoop03）
            略
        启动集群（hadoop01）
            cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
            sbin/start-all.sh
                验证
                    jps 
                    http://hadoop01:8080
        测试应用提交
            cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
            bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://hadoop01:7077 examples/jars/spark-examples_2.12-3.0.0.jar 10
                --class：执行程序主函数的类。
                --master spark://hadoop01:7077：独立部署模式，连接到Spark集群。
                spark-examples_2.12-3.0.0.jar：执行程序的Jar包。
                10：主函数的入参。
        配置历史服务 
            集群监控http://hadoop01:4040默认看不到历史任务情况，需要配置历史服务。
            前置条件
                Hadoop集群已经启动（hadoop01，hadoop02，hadoop03）。
                HDFS上已经创建目录/directory。
            修改配置文件（hadoop01）
                cp /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-defaults.conf.template /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-defaults.conf 
                vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-defaults.conf
                    追加
                        spark.eventLog.enabled             true
                        spark.eventLog.dir                 hdfs://hadoop01:8020/directory
                vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh
                    追加
                        export SPARK_HISTORY_OPTS="
                        -Dspark.history.ui.port=18080
                        -Dspark.history.fs.logDirectory=hdfs://hadoop01:8020/directory
                        -Dspark.history.retainedApplications=30"
            分发配置文件到集群（hadoop02，hadoop03）
                略
            启动历史服务（hadoop01）
                cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
                sbin/stop-all.sh
                sbin/start-all.sh
                sbin/start-history-server.sh
                    验证
                        jps
                        http://hadoop01:18080/
            测试应用提交
                略
        配置高可用
            当前Master节点只有一个，存在单点故障问题。要达到高可用，需要配置多个备用的Master。
            前置条件
                已经启动ZooKeeper集群（hadoop01，hadoop02，hadoop03）
                高可用规划
                    hadoop01
                        Master 
                        ZooKeeper 
                        Worker
                    hadoop02
                        Master 
                        ZooKeeper 
                        Worker
                    hadoop03
                        ZooKeeper 
                        Worker
            修改配置文件（hadoop01）
                vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh
                    更新或追加
                        # export SPARK_MASTER_HOST=hadoop01
                        # export SPARK_MASTER_PORT=7077
                        
                        SPARK_MASTER_WEBUI_PORT=8989
                        export SPARK_DAEMON_JAVA_OPTS="
                        -Dspark.deploy.recoveryMode=ZOOKEEPER
                        -Dspark.deploy.zookeeper.url=hadoop01,hadoop02,hadoop03
                        -Dspark.deploy.zookeeper.dir=/spark"
            分发配置文件到集群（hadoop02，hadoop03）
                略
            重启集群（hadoop01）
                cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
                sbin/stop-all.sh
                sbin/start-all.sh
                    验证
                        http://hadoop01:8989
            启动备用Master（hadoop02）
                cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
                sbin/start-master.sh
            测试应用提交
                cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
                bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://hadoop01:7077,hadoop02:7077 examples/jars/spark-examples_2.12-3.0.0.jar 10
                    停止Master进程（hadoop01），再次测试。
    YARN模式
        YARN模式下，Spark的资源由YARN调度。
        前置条件
            三台服务器（Ubuntu 20.04.6 LTS）
                192.168.233.129 hadoop01
                192.168.233.130 hadoop02
                192.168.233.131 hadoop03
            Hadoop集群已经启动（hadoop01，hadoop02，hadoop03。包含YARN服务）。
        准备文件（hadoop01）
            sudo mkdir /opt/module/spark 
            sudo chown -R sxydh:sxydh /opt/module/spark
            wget -P /opt/module/spark https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz
            tar -zxvf /opt/module/spark/spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module/spark
        修改配置文件（hadoop01）
            cp /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh.template /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh
            vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh
                追加
                    export JAVA_HOME=/opt/module/jdk/jdk1.8.0_202
                    YARN_CONF_DIR=/opt/module/hadoop/hadoop-3.1.3/etc/hadoop
        测试应用提交（hadoop01）
            cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
            bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode cluster examples/jars/spark-examples_2.12-3.0.0.jar 10
                验证
                    http://hadoop02:8088
        配置历史服务
            前置条件
                HDFS上已经创建目录/directory。
            修改配置文件（hadoop01）
                cp /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-defaults.conf.template /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-defaults.conf 
                vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-defaults.conf
                    追加
                        spark.eventLog.enabled             true
                        spark.eventLog.dir                 hdfs://hadoop01:8020/directory
                        
                        spark.yarn.historyServer.address=hadoop01:18080
                        spark.history.port=18080
                vim /opt/module/spark/spark-3.0.0-bin-hadoop3.2/conf/spark-env.sh
                    追加
                        export SPARK_HISTORY_OPTS="
                        -Dspark.history.ui.port=18080
                        -Dspark.history.fs.logDirectory=hdfs://hadoop01:8020/directory
                        -Dspark.history.retainedApplications=30"
            启动历史服务（hadoop01）
                cd /opt/module/spark/spark-3.0.0-bin-hadoop3.2/
                sbin/start-history-server.sh
                    验证
                        jps
            测试应用提交（hadoop01）
                bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client examples/jars/spark-examples_2.12-3.0.0.jar 10
                    验证
                        http://hadoop02:8088
                            Applications
                                History